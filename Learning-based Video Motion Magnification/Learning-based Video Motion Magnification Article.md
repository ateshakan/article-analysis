# Abstract
Video [[motion magnification]] techniques allow us to see small motions previously invisible to the naked eyes, such as those of vibrating airplane wings, or swaying buildings under the influence of the wind. Because the motion is small, the magnification results are prone to noise or excessive blurring. The state of art relies on hand designed filters to extract representations that may not be optimal. In this paper, we seek to learn the filters directly from examples using deep CNNs. To make training tractable, we carefully design a [[synthetic dataset]] that captures small motion well, and use two-frame input for training. We show that the learned filters achieve high-quality results on real videos, with less ringing artifacts and better noise characteristics tan previous methods. While our model isn't trained with [[temporal filters]], we found that the temporal filters can be used with our extracted representations up to a moderate magnification, enabling a frequency-based motion selection. Finally, we analyze the learned filters and show that they behave similarly to the [[derivative filters]] used in previous works. 
# Motivation
## Limitations of existing video motion magnification techniques:
Video motion magnification techniques can be divided into two categories: [[Lagrangian]] and [[Eulerian]] approaches. Lagrangian approaches extract the motion field (optical flow) and directly move the pixels based on it. On the other hand, Eulerian approaches, including techniques like those by Wu et al. 30 and Wadhwa et al. 26, 27, decompose video frames into representations that enable motion manipulation without explicit tracking. These techniques typically involve decomposing frames, manipulating the representation, and reconstructing it to obtain magnified frames.
However, current Eulerian techniques have certain limitations. While they excel at revealing subtle motions, they are often hand-designed and fail to address issues such as occlusion. As a result, they are prone to noise and excessive blurring. In contrast, our proposed technique belongs to the Eulerian approach, but our decomposition is directly learned from examples. This approach leads to fewer edge artifacts and better noise characteristics.
# Methodology
